{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81aca741-ffc9-4724-a377-d128e4bc5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5185a421-868f-4fd5-92c5-60975668c810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\mlp\\Animal classification\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "878cd76a-2345-478d-96ff-41d0149e8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n",
      "Class names: ['cats', 'dogs', 'snakes']\n",
      "cats: 1000 images\n",
      "dogs: 1000 images\n",
      "snakes: 1000 images\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r'C:\\Users\\user\\anaconda3\\envs\\mlp\\Animal classification\\Dataset'\n",
    "classes = os.listdir(dataset_path)\n",
    "print(\"Number of classes:\", len(classes))\n",
    "print(\"Class names:\", classes[:])  \n",
    "for cls in classes:\n",
    "    print(f\"{cls}: {len(os.listdir(os.path.join(dataset_path, cls)))} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561f8dd-f6c6-40ec-9982-311042d45939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "def load_and_split_dataset(data_dir, train_size=0.7, val_size=0.15, output_dir=\"split_dataset\", random_state=42):\n",
    "    \"\"\"\n",
    "    Loads images from class folders and splits them into training, validation, and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    data_dir: path to dataset directory containing 'cat', 'dog', 'snake' folders\n",
    "    train_size: proportion of data for training\n",
    "    val_size: proportion of data for validation\n",
    "    output_dir: directory to save split datasets\n",
    "    random_state: seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with split file paths and labels\n",
    "    \"\"\"\n",
    "    # Defining classes and splitings\n",
    "    classes = ['cat', 'dog', 'snake']\n",
    "    test_size = 1.0 - train_size - val_size\n",
    "    \n",
    "    # Initializing lists to store file paths and labels\n",
    "    split_data = {\n",
    "        'train': {'files': [], 'labels': []},\n",
    "        'val': {'files': [], 'labels': []},\n",
    "        'test': {'files': [], 'labels': []}\n",
    "    }\n",
    "    \n",
    "    # Creating output directories\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n",
    "    \n",
    "    # Processing each class\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(data_dir, cls)\n",
    "        if not os.path.exists(class_dir):\n",
    "            raise FileNotFoundError(f\"Directory {class_dir} not found\")\n",
    "        \n",
    "        # Get all image files\n",
    "        files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        if len(files) != 1000:\n",
    "            print(f\"Warning: Found {len(files)} images in {class_dir}, expected 1000\")\n",
    "        \n",
    "        # Create labels for this class\n",
    "        labels = [cls] * len(files)\n",
    "        \n",
    "        # First split: train vs (val + test)\n",
    "        train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "            files, labels, train_size=train_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Adjust val_size for second split\n",
    "        relative_val_size = val_size / (val_size + test_size)\n",
    "        \n",
    "        # Second split: val vs test\n",
    "        val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "            temp_files, temp_labels, train_size=relative_val_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Store in split_data\n",
    "        split_data['train']['files'].extend(train_files)\n",
    "        split_data['train']['labels'].extend(train_labels)\n",
    "        split_data['val']['files'].extend(val_files)\n",
    "        split_data['val']['labels'].extend(val_labels)\n",
    "        split_data['test']['files'].extend(test_files)\n",
    "        split_data['test']['labels'].extend(test_labels)\n",
    "        \n",
    "        # Copy files to output directories\n",
    "        for split, split_files in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
    "            for file_path in split_files:\n",
    "                dest_path = os.path.join(output_dir, split, cls, os.path.basename(file_path))\n",
    "                shutil.copy(file_path, dest_path)\n",
    "    \n",
    "    # Print summary\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        print(f\"{split.capitalize()} set: {len(split_data[split]['files'])} images\")\n",
    "        for cls in classes:\n",
    "            cls_count = split_data[split]['labels'].count(cls)\n",
    "            print(f\"  {cls}: {cls_count} images\")\n",
    "    \n",
    "    return split_data\n",
    "\n",
    "# Example usage\n",
    "# data_dir = \"path/to/your/dataset\"  # Directory with 'cat', 'dog', 'snake' folders\n",
    "# split_data = load_and_split_dataset(data_dir, output_dir=\"split_animal_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
